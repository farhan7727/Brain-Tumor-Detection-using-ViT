{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1_52YIAut6R-"
      },
      "outputs": [],
      "source": [
        "import tqdm as notebook_tqdm\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0eVptTSuCo9"
      },
      "outputs": [],
      "source": [
        "# --- Define Constants ---\n",
        "CLASSIFICATION_MODEL_PATH = 'brain_tumor_vit_model_5extra.h5'\n",
        "SEGMENTATION_MODEL_PATH = 'seg_model_v2.h5'\n",
        "CLASS_NAMES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "IMAGE_SIZE = (224, 224)\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "# --- Utility Functions ---\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super(Patches, self).__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'patch_size': self.patch_size})\n",
        "        return config\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
        "        super(PatchEncoder, self).__init__(**kwargs)\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'num_patches': self.num_patches, 'projection_dim': self.projection_dim})\n",
        "        return config\n",
        "\n",
        "\n",
        "def create_dummy_models_if_not_exist():\n",
        "    \"\"\"Checks for model files and creates dummy ones if they are missing.\"\"\"\n",
        "\n",
        "    # --- Classification Model (ViT) ---\n",
        "    if not os.path.exists(CLASSIFICATION_MODEL_PATH):\n",
        "        print(f\"Placeholder classification model not found. Creating a dummy model at: {CLASSIFICATION_MODEL_PATH}\")\n",
        "\n",
        "        patch_size = 16\n",
        "        num_patches = (IMAGE_SIZE[0] // patch_size) ** 2\n",
        "        projection_dim = 64\n",
        "\n",
        "        inputs = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1))\n",
        "        patches = Patches(patch_size)(inputs)\n",
        "        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "        flattened = layers.Flatten()(encoded_patches)\n",
        "        outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(flattened)\n",
        "\n",
        "        dummy_cls_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "        dummy_cls_model.save(CLASSIFICATION_MODEL_PATH)\n",
        "        print(\"Dummy classification model created.\")\n",
        "\n",
        "    # --- Segmentation Model ---\n",
        "    if not os.path.exists(SEGMENTATION_MODEL_PATH):\n",
        "        print(f\"Placeholder segmentation model not found. Creating a dummy model at: {SEGMENTATION_MODEL_PATH}\")\n",
        "\n",
        "        inputs = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1))\n",
        "        conv1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n",
        "        outputs = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv1)\n",
        "\n",
        "        dummy_seg_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "        dummy_seg_model.save(SEGMENTATION_MODEL_PATH)\n",
        "        print(\"Dummy segmentation model created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "3WyGP0dnwzMM",
        "outputId": "a54f7197-f86c-4353-f1a4-00cb66b61d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading models... This may take a moment.\n",
            "WARNING:tensorflow:From d:\\APPS\\Conda\\envs\\py1\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# --- Loading the Model ---\n",
        "create_dummy_models_if_not_exist()\n",
        "\n",
        "print(\"\\nLoading models... This may take a moment.\")\n",
        "try:\n",
        "    classification_model = tf.keras.models.load_model(\n",
        "        CLASSIFICATION_MODEL_PATH,\n",
        "        custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder}\n",
        "    )\n",
        "    segmentation_model = tf.keras.models.load_model(SEGMENTATION_MODEL_PATH, compile=False)\n",
        "    print(\"Models loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading models: {e}\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf3X92QNuSSg"
      },
      "outputs": [],
      "source": [
        "# --- Preprocessing ---\n",
        "def predict(input_image):\n",
        "    \"\"\"\n",
        "    Takes a user-uploaded image, runs it through both models,\n",
        "    and returns the classification and segmentation results.\n",
        "    \"\"\"\n",
        "    if input_image is None:\n",
        "        return None, None\n",
        "\n",
        "    image = Image.fromarray(input_image)\n",
        "\n",
        "    # Classification\n",
        "    img_gray_cls = image.convert('L')\n",
        "    img_resized_cls = img_gray_cls.resize(IMAGE_SIZE, Image.Resampling.LANCZOS)\n",
        "    img_np_cls = np.array(img_resized_cls)\n",
        "    img_equalized_cls = cv2.equalizeHist(img_np_cls)\n",
        "    img_final_cls = img_equalized_cls.astype('float32') / 255.0\n",
        "    img_final_cls = np.expand_dims(img_final_cls, axis=-1)\n",
        "    img_final_cls = np.expand_dims(img_final_cls, axis=0)\n",
        "    class_prediction = classification_model.predict(img_final_cls)[0]\n",
        "    confidences = {CLASS_NAMES[i]: float(class_prediction[i]) for i in range(len(CLASS_NAMES))}\n",
        "\n",
        "    # Segmentation\n",
        "    img_rgb_seg = image.convert('RGB')\n",
        "    img_resized_seg = img_rgb_seg.resize(IMAGE_SIZE, Image.Resampling.LANCZOS)\n",
        "    img_np_seg = np.array(img_resized_seg)\n",
        "    img_final_seg = img_np_seg.astype('float32') / 255.0\n",
        "    img_final_seg = np.expand_dims(img_final_seg, axis=0)\n",
        "    seg_mask = segmentation_model.predict(img_final_seg)[0]\n",
        "    seg_mask = np.squeeze((seg_mask * 255).astype(np.uint8))\n",
        "\n",
        "    return confidences, seg_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PkPesraVuUhz"
      },
      "outputs": [],
      "source": [
        "# --- 3. Gradio Interface ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Brain Tumor Analysis: Classification & Segmentation\n",
        "        Upload a MRI brain scan to classify the tumor type and generate a segmentation mask.\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_image = gr.Image(type=\"numpy\", label=\"Upload MRI Image\")\n",
        "            submit_btn = gr.Button(\"Analyze Image\", variant=\"primary\")\n",
        "        with gr.Column():\n",
        "            output_label = gr.Label(num_top_classes=4, label=\"Classification Results\")\n",
        "            output_segmentation = gr.Image(label=\"Segmentation Mask\")\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=predict,\n",
        "        inputs=input_image,\n",
        "        outputs=[output_label, output_segmentation]\n",
        "    )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[],\n",
        "        inputs=input_image,\n",
        "        outputs=[output_label, output_segmentation],\n",
        "        fn=predict,\n",
        "        cache_examples=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "LAseFjLGuV8r",
        "outputId": "6425f072-c538-4ae9-f30e-13428c92ba95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching Gradio app...\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "Caching examples at: 'd:\\Research\\Barin Tumor MRI\\Brain Tumor Detector\\.gradio\\cached_examples\\19'\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ],
      "source": [
        "# --- 4. Launch the App ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Launching Gradio app...\")\n",
        "    demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
